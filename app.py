import streamlit as st
from dotenv import load_dotenv
import os
from PyPDF2 import PdfReader
from langchain.text_splitter import CharacterTextSplitter
import hashlib

# (deprecatd) from langchain.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings
from langchain_community.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings

# (deprecatd) from langchain.vectorstores import FAISS # ë¬¸ì„œê²€ìƒ‰ì„ ë‹´ë‹¹í•˜ëŠ” í˜ì´ìŠ¤ë¶ì´ ë§Œë“  ê³ ì† Vector DB. ë¡œì»¬ì— ì„¤ì¹˜í•˜ë©°, í”„ë¡œê·¸ë¨ ì¢…ë£Œì‹œ DBëŠ” ì‚­ì œë¨
from langchain_community.vectorstores import FAISS

from htmlTemplates import css, bot_template, user_template   # htmlTemplates.py íŒŒì¼ì•ˆì— ìˆëŠ” ëª¨ë“ˆë“¤ì„ ê°€ì ¸ì˜´

def get_pdf_text(pdf_docs):
    # ë¹ˆ text ë°°ì—´ ìƒì„±
    text = ""
    for pdf in pdf_docs:
        # í˜ì´ì§€ë³„ë¡œ ë°°ì—´ì„ ë¦¬í„´í•´ì£¼ëŠ” PdfReaderí´ë˜ìŠ¤ì˜ ê°ì²´ ìƒì„±
        pdf_reader = PdfReader(pdf)
        for page in pdf_reader.pages:
            # ê° í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì—¬ ëª¨ë“  textë¥¼ ë°°ì—´ë¡œ ì €ì¥ --> extract_text ë§¤ì†Œë“œë¥¼ ì´ìš©
            text += page.extract_text()
    return text

def get_text_chunk(text):
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=1000,
        chunk_overlap=200,
        length_function=len
    )
    chunks = text_splitter.split_text(text)
    return chunks

def get_vectorstore(text_chunks):
    ##############################
    #     embedding API ì„ íƒ      #
    ##############################

    # ì„ íƒ 1: OpenAI embedding API ì‚¬ìš©ì‹œ (ìœ ë£Œ)
    embeddings = OpenAIEmbeddings()

    # ì„ íƒ 2: í—ˆê¹…í˜ì´ìŠ¤ì—ì„œ ì œê³µí•˜ëŠ” Instructor embedding API ì‚¬ìš©ì‹œ (ë¬´ë£Œ)
    # ì„±ëŠ¥ì€ OpenAIEmbeddingsë³´ë‹¤ ìš°ìˆ˜í•˜ì§€ë§Œ ëŠë¦¬ë‹¤.
    # https://huggingface.co/hkunlp/instructor-xl
    # model_name ì¸ìê°’ìœ¼ë¡œ hkunlp/instructor-xlì„ ì…ë ¥
    # ë‹¨, 2ê°œì˜ dependencyë¥¼ ì„¤ì¹˜í•´ì•¼ í•¨ pip install instructorembedding sentence_transformers
    # embeddings = HuggingFaceInstructEmbeddings(model_name="hkunlp/instructor-xl")
    vectorstore = FAISS.from_texts(texts=text_chunks, embedding=embeddings)
    return vectorstore

# get_conversation_chain(vectorscore) ì‹¤í–‰ì— í•„ìš”í•œ ëª¨ë“ˆ
# (deprecated) from langchain.chat_models import ChatOpenAI # ConversationBufferMemory()ì˜ ì¸ìë¡œ ë“¤ì–´ê°ˆ llmìœ¼ë¡œ ChatOpenAIëª¨ë¸ì„ ì‚¬ìš©í•˜ê¸°ë¡œ í•¨
from langchain_community.chat_models import ChatOpenAI

from langchain.memory import ConversationBufferMemory # ëŒ€í™”ë‚´ìš©ì„ ì €ì¥í•˜ëŠ” memory
from langchain.chains import ConversationalRetrievalChain

######################################################
#  í•µì‹¬ í•¨ìˆ˜ GCC : get_conversation_chain(vectorscore) #
######################################################
# ì…ë ¥ : VectorDB
# ì¶œë ¥ : ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ DB ê²€ìƒ‰ê³¼ ê²°ê³¼ì¶œë ¥ì„ ë‹´ë‹¹í•˜ëŠ” ConversationalRetrievalChain.from_llmì˜ ê°ì²´ë¥¼ ìƒì„±í•˜ì—¬ ë°˜í™˜í•¨
def get_conversation_chain(vectorscore):
   # ë©”ëª¨ë¦¬ì— ë¡œë“œëœ envíŒŒì¼ì—ì„œ "OPENAI_API_KEY"ë¼ê³  ëª…ëª…ëœ ê°’ì„ ë³€ìˆ˜ë¡œ ì €ì¥
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    # ì„ íƒ 1: ëŒ€í™”ì— ì‚¬ìš©ë  llm API ê°ì²´ë¥¼ llm ë³€ìˆ˜ì— ì €ì¥
    llm = ChatOpenAI(
        temperature=0.1,    # ì°½ì˜ì„± (0.0 ~ 2.0)
        model_name="gpt-4-turbo-preview", # chatGPT-4 Turbo ì‚¬ìš©
        openai_api_key=OPENAI_API_KEY # Automatically inferred from env var OPENAI_API_KEY if not provided.
        )

    # ì„ íƒ 2: HuggingFaceHubë¥¼ llm ëª¨ë¸ë¡œ ì‚¬ìš©ì‹œ
    # from langchain.llms import HuggingFaceHub
    # llm = HuggingFaceHub(repo_id="google/flan-t5-xxl", model_kwargs={"temperature":0.5, "max_length":512})

    # ConverstaionBufferMemory í´ë˜ìŠ¤ë¥¼ ì´ìš©í•˜ì—¬ ëŒ€í™”ë‚´ìš©ì„ chat_historyë¼ëŠ” keyê°’ìœ¼ë¡œ ì €ì¥í•´ì£¼ëŠ” memory ê°ì²´ë¥¼ ìƒì„±
    memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

    # llm ê°ì²´, memory ê°ì²´ë¥¼ ì¸ìë¡œ ì…ë ¥í•˜ì—¬ DB ê²€ìƒ‰ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ëŠ” ConversationalRetrievalChain.from_llm ê°ì²´ë¥¼ ìƒì„±
    conversation_chain = ConversationalRetrievalChain.from_llm(
        # ê²€ìƒ‰ì„ ì‹¤í–‰í•˜ëŠ” llm ì„ íƒ
        llm=llm,
        # ê²€ìƒ‰ì„ ë‹¹í•˜ëŠ” vector DBë¥¼ retriver í¬ë§·ìœ¼ë¡œ ì €ì¥
        retriever=vectorscore.as_retriever(),
        # ì‚¬ìš©ìì™€ ëŒ€í™”ë‚´ìš©ì„ ë©”ëª¨ë¦¬ì— ì €ì¥í•˜ì—¬ ê°™ì€ ë§¥ë½ì—ì„œ ëŒ€í™”ë¥¼ ìœ ì§€
        memory=memory
    )
    # ConversationalRetrievalChain.from_llm ê°ì²´ë¡œ ìƒì„±ëœ convestaion_chainì„ ë°˜í™˜
    return conversation_chain

######################################################
#              í•µì‹¬ í•¨ìˆ˜ handle_userinput              #
######################################################
# userì— ë°›ì€ ì§ˆë¬¸ì„ ì¸ìë¡œ ë„£ìœ¼ë©´ ëŒ€ë‹µì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
# í•µì‹¬í•¨ìˆ˜ GCCì— ì˜í•´ ìƒì„±ëœ st.session_sate.converstaion ê°ì²´ì˜ ë©”ì†Œë“œë¥¼ í™œìš©í•˜ì—¬ ëŒ€ë‹µì„ ìƒì„±í•¨
def handle_userinput(user_question) :
    # ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ DB ê²€ìƒ‰ê³¼ ê²°ê³¼ì¶œë ¥ì„ ë‹´ë‹¹í•˜ëŠ” ConversationalRetrievalChain.from_llmì˜ ê°ì²´ë¡œ ìƒì„±ëœ ê²ƒì´
    # st.sessioin_state.conversation
    # ë”°ë¼ì„œ ê°ì²´ì˜ ë©”ì†Œë“œë¡œì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì€ ({'question': user_question}) í˜•íƒœë¡œ ì¸ìì— ë„£ì–´ì£¼ë©´ ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ê³ , ëŒ€í™”ë‚´ìš©ì€ ë©”ëª¨ë¦¬ì— ì €ì¥ëœë‹¤.
    # response['chat_history']ì—ëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ëŒ€ë‹µì´ ì €ì¥ë˜ì–´ ìˆë‹¤.
    response = st.session_state.conversation({'question': user_question}) # ê°ì²´ì˜ ë‚´ì¥ë©”ì†Œë“œì— ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°›ëŠ” ê¸°ëŠ¥ì´ ìˆì„ ê²ƒì„
    # st.write(response) # ë”•ì…”ë„ˆë¦¬ë¡œ ì¶œë ¥ë˜ë©° chat_historyë¼ëŠ” keyê°’ì— ì§ˆì˜/ì‘ë‹µì´ ì €ì¥ë˜ì–´ ìˆìŒì„ ì•Œìˆ˜ìˆë‹¤.

    # 'chat_history'ë¥¼ keyê°’ìœ¼ë¡œ í•˜ì—¬ ì´ë²ˆì˜ ì§ˆì˜ì‘ë‹µë§Œ ì €ì¥ë˜ì–´ ìˆëŠ”ë°, ì´ë¥¼ ë©”ëª¨ë¦¬ì— ëˆ„ì ì—ì„œ ë³´ê´€í•˜ì—¬ ì „ì²´ ëŒ€í™”ë¥¼ ê¸°ë¡í•¨
    st.session_state.chat_history = response['chat_history']

    # message ê°ì²´ì˜ content ì†ì„±ì— ëŒ€í™”ê°€ ë“¤ì–´ìˆìœ¼ë¯€ë¡œ ì´ë¥¼ ì¶”ì¶œí•˜ì—¬ íƒ¬í”Œë¦¿ì˜ {{MSG}} ìœ„ì¹˜ì— ë„£ëŠ” replace ë©”ì†Œë“œë¥¼ ì‚¬ìš©
    for i, message in enumerate(st.session_state.chat_history):
        if i % 2 == 0:
            st.write(user_template.replace(
                "{{MSG}}", message.content), unsafe_allow_html=True)
        else:
            st.write(bot_template.replace(
                "{{MSG}}", message.content), unsafe_allow_html=True)

######################################################
#                    admin key ê²€ì¦                   #
######################################################

def is_admin(_input_key):
    # ë¬¸ìì—´ì„ byteì—´ë¡œ encodingì„ ë¨¼ì € ì‹¤ì‹œí•œ í›„, sha256ìœ¼ë¡œ ì•”í˜¸í™”
    input_key_hash = hashlib.sha256(_input_key.encode()).hexdigest()
    saved_key_hash = hashlib.sha256(os.getenv("OPENAI_API_KEY").encode()).hexdigest()
    if input_key_hash == saved_key_hash :
        return True

###############################
#          (ì°¸ê³ )  ì±„íŒ…ì°½        #
###############################
# ì‚¬ì „ì— ì •ì˜í•œ css, htmlì–‘ì‹ì„ st.wirte() í•¨ìˆ˜ì˜ ì¸ìë¡œ ë„£ì–´ì£¼ë©´ ì›¹ì‚¬ì´íŠ¸ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•œë‹¤.
# st.write(user_template.replace("{{MSG}}", "Hellow Bot"), unsafe_allow_html=True)
# st.write(bot_template.replace("{{MSG}}", "Hellow Human"), unsafe_allow_html=True)

######################################################
#                        Main                        #
######################################################

def main() :
    load_dotenv()
    st.set_page_config(page_title="TONchat", page_icon=":books:", layout="wide")
    # css, htmlê´€ë ¨ ì„¤ì •ì€ ì‹¤ì œ ëŒ€í™”ê´€ë ¨ í•¨ìˆ˜ë³´ë‹¤ ì•ì—ì„œ ë¯¸ë¦¬ ì‹¤í–‰í•´ì•¼ í•œë‹¤.
    st.write(css, unsafe_allow_html=True)


    ###############################
    #             ì´ˆê¸°í™”            #
    ###############################

    # st.session_state.conversation = get_conversation_chain(vectorstore)ì„ í†µí•´
    # sesstion_state ê°ì²´ì˜ ì†ì„±ìœ¼ë¡œ conversationì´ ì‹ ì„¤ë˜ê³ , ê·¸ ì•ˆì— ë”•ì…”ë„ˆë¦¬ë¡œ ì§ˆì˜/ì‘ë‹µì´ ì €ì¥ëœë‹¤.
    # { question : ddd, answer : ddd } ì´ëŸ°ì‹ì´ë‹¤.
    # ì´ëŸ¬í•œ ì €ì¥ì´ ì´ë¤„ì§€ë„ë¡ ì¼ë‹¨ conversation ì†ì„±ì— Noneìœ¼ë¡œ ì´ˆê¸°í™”ë¥¼ ì‹œì¼œ ì¤€ë¹„í•´ë†“ëŠ”ë‹¤.
    if "conversation" not in st.session_state:
        st.session_state.conversation = None

    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = None

    ###############################
    #             ì§ˆë¬¸ì°½            #
    ###############################
    # ì§ˆë¬¸ì…ë ¥ì°½
    st.header("TONchat")
    st.write("Ask a question about Tokamak Network's services")
    st.write("- Titan L2 Network")
    st.write("")
    user_question = st.text_input("Input your question")
    # ì§ˆë¬¸ì´ ì €ì¥ë˜ë©´ ifë¬¸ì´ trueê°€ ë˜ê³ , ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì²˜ë¦¬í•œë‹¤.
    if user_question:
        handle_userinput(user_question)


    ###############################
    #      sidebar íŒŒì¼ ì—…ë¡œë“œ       #
    ###############################
    with st.sidebar:
        # Admin login
        with st.popover("Admin login"):
            st.markdown("Admin key ğŸ”‘")
            admin = is_admin(st.text_input("Input your admin key"))
        if admin :
            st.write("Hi, Admin !")
            logout = st.button("Logout", type="primary")
            st.header("Your documents")
            # upload multiple documents
            pdf_docs = st.file_uploader("Upload your PDFs here and click on 'process'", accept_multiple_files=True)
            if st.button("Process") :
                with st.spinner('Processing') :
                    ########################
                    #      get pdf text    #
                    ########################
                    raw_text = get_pdf_text(pdf_docs)

                    ########################
                    #  get the text chunks #
                    ########################
                    text_chunks = get_text_chunk(raw_text)
                    st.write(text_chunks)

                    ########################
                    #  create vector store #
                    ########################
                    vectorstore = get_vectorstore(text_chunks)

                    ########################################
                    #  í•µì‹¬í•¨ìˆ˜ë¥¼ ì´ìš©í•œ conversation chain ìƒì„± #
                    ########################################
                    # í•µì‹¬í•¨ìˆ˜ get_conversation_chain() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬, ì²«ì§¸, ì´ì „ ëŒ€í™”ë‚´ìš©ì„ ì½ì–´ë“¤ì´ê³ , ë‘˜ì§¸, ë‹¤ìŒ ëŒ€í™” ë‚´ìš©ì„ ë°˜í™˜í•  ìˆ˜ ìˆëŠ” ê°ì²´ë¥¼ ìƒì„±
                    # ë‹¤ë§Œ streamlit í™˜ê²½ì—ì„œëŠ” inputì´ ì¶”ê°€ë˜ê±°ë‚˜, ì‚¬ìš©ìê°€ ë²„íŠ¼ì„ ëˆ„ë¥´ê±°ë‚˜ í•˜ëŠ” ë“± ìƒˆë¡œìš´ ì´ë²¤íŠ¸ê°€ ìƒê¸°ë©´ ì½”ë“œ ì „ì²´ë¥¼ ë‹¤ì‹œ ì½ì–´ë“¤ì„
                    # ì´ ê³¼ì •ì—ì„œ ë³€ìˆ˜ê°€ ì „ë¶€ ì´ˆê¸°í™”ë¨.
                    # ë”°ë¼ì„œ ì´ëŸ¬í•œ ì´ˆê¸°í™” ë° ìƒì„±ì´ ë°˜ë³µë˜ë©´ ì•ˆë˜ê³  í•˜ë‚˜ì˜ ëŒ€í™” ì„¸ì…˜ìœ¼ë¡œ ê³ ì •í•´ì£¼ëŠ” st.sessiion_state ê°ì²´ì•ˆì— ëŒ€í™”ë¥¼ ì €ì¥í•´ì•¼ ë‚ ì•„ê°€ì§€ ì•ŠìŒ
                    # conversationì´ë¼ëŠ” ì†ì„±ì„ ì‹ ì„¤í•˜ê³  ê·¸ ì•ˆì— ëŒ€í™”ë‚´ìš©ì„ key, value ìŒìœ¼ë¡œ ì €ì¥ (ë”•ì…”ë„ˆë¦¬ ìë£Œí˜•)
                    st.session_state.conversation = get_conversation_chain(vectorstore)
            else:
                st.write("You are not admin")

if __name__ == "__main__":
    main()